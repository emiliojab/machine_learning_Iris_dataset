{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris Dataset\n",
    "### In this notebook, many Machine Learning Algorithms were implemented on the Iris Dataset.\n",
    "### The Iris Dataset is one of the \"Hello World\" problems in Machine Learning.\n",
    "\n",
    "The Machine Learning **(ML)** Algorithms used are:\n",
    "* __[Supervised Learning:](https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning#:~:text=for%20your%20situation.-,What%20is%20supervised%20learning%3F,-Supervised%20learning%20is)__\n",
    "    * __[Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__\n",
    "    * __[Decision Tree](https://scikit-learn.org/stable/modules/tree.html)__\n",
    "    * __[Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)__\n",
    "    * __[XGBoost](https://xgboost.readthedocs.io/en/stable/install.html)__\n",
    "<br><br>\n",
    "* __[Unsupervised Learning:](https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning#:~:text=and%20polynomial%20regression.-,What%20is%20unsupervised%20learning%3F,-Unsupervised%20learning%20uses)__\n",
    "    * __[K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)__<br>\n",
    "<br>\n",
    "\n",
    "### Below are some basic explanations, from the *[Machine Learning Specialization - DeepLearning.AI](https://www.deeplearning.ai/courses/machine-learning-specialization/)* courses.\n",
    "#### Supervised Learning \n",
    "It is the use of labeled datasets to train ML algorithms.\n",
    "During training, the input $x$ is mapped to the output $y$. If trained well, the algorithm will be able to predict unseen data.\n",
    "Many factors tell if the ML model is trained well, such as the Gradient Descent where the input trainng data is utilized to fit the parameters w, b (or the weights) by minimizing the measure of the error between the model's predictions $f_{w,b}(x^{(i)})$, and the actual data $y^{(i)}$.\n",
    "The measure is called the cost $J(w,b)$ where:\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "In this notebook, we are using Classification. Therefore, the classification loss function loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right is discribed as follow:\n",
    "$$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "And the Gradient Descent is a loop where we substract the partial derivative from the weights simultaneously:\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously *(calculating the partial derivatives for all the parameters before updating any of the parameters)*.  \n",
    "The gradient is defined as:\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}  \\; \\newline \n",
    "\\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})  \\newline \n",
    "\\end{align}$$\n",
    "Where $m$ is the number of training examples.\n",
    "<br><br>\n",
    "In this notebook, the Supervised Learning Algorithms are implemented with the __[$sklearn$](https://scikit-learn.org/stable/)__ library.\n",
    "### Unsupervised Learning\n",
    "It is the use of ML algorithms to identify patterns in data sets containing data points thar are neither classified nor labaled.\n",
    "<br>In this notebook the $K$-means is used as an Unsupervised Learning Algorithm.\n",
    "<br>The $K$-means algorithm is a method to automatically cluster similar\n",
    "data points together. \n",
    "\n",
    "* It is the practive of grouping a training set $\\{x^{(1)}, ..., x^{(m)}\\}$,  into a few cohesive “clusters”. \n",
    "<br><br>\n",
    "* $K$-means is an iterative procedure that\n",
    "    * Starts by guessing the initial centroids, and then \n",
    "    * Refines this guess by \n",
    "        * Repeatedly assigning examples to their closest centroids, and then \n",
    "        * Recomputing the centroids based on the assignments.       \n",
    "<br><br>\n",
    "* The inner-loop of the algorithm repeatedly carries out two steps: \n",
    "    * (i) Assigning each training example $x^{(i)}$ to its closest centroid, and\n",
    "    * (ii) Recomputing the mean of each centroid using the points assigned to it.    \n",
    "<br><br>\n",
    "* The $K$-means algorithm will always converge to some final set of means for the centroids. \n",
    "<br><br>\n",
    "* However, that the converged solution may not always be ideal and depends on the initial setting of the centroids.\n",
    "    * Therefore, in practice the $K$-means algorithm is usually run a few times with different random initializations. \n",
    "    * One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function value (distortion).\n",
    "<br><br>\n",
    "* In this notebook the $K$-means is implemented in two ways:\n",
    "    * Implementing the algorithms with $numpy$\n",
    "    * Using the $sklearn$ Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing many Libraries and Frameworks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ML Projects\\to_git\\Iris\\iris.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ML%20Projects/to_git/Iris/iris.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlines\u001b[39;00m \u001b[39mimport\u001b[39;00m Line2D\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ML%20Projects/to_git/Iris/iris.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# for building ML models\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ML%20Projects/to_git/Iris/iris.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m tree\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ML%20Projects/to_git/Iris/iris.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msvm\u001b[39;00m \u001b[39mimport\u001b[39;00m SVC\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ML%20Projects/to_git/Iris/iris.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# for processing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# for building ML models\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import auc, accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from yellowbrick.classifier import PrecisionRecallCurve, ROCAUC, ConfusionMatrix\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.model_selection import LearningCurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Pandas](https://pandas.pydata.org/)** is the best tool for reading *.csv* (and others) files and transforming them into tables, or what is called **Pandas Dataframes**\n",
    "<br>\n",
    "* Here we can see that we have 6 columns.\n",
    "    * **Id**, the id of each record. It is not needed while training our models, it has not any representation of any of the training examples.\n",
    "    * **SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm**, these are the features of each of the Iris flower, and each combination of them are properties of a certain Species.\n",
    "    * **Species**, is the lablel of each record. As we can see, we have three species:\n",
    "        * Iris-setosa\n",
    "        * Iris-versicolor\n",
    "        * Iris-virginica\n",
    "\n",
    "### **The problem**\n",
    "The problem here is to classify an Iris flower (under which Species does it fall), given just the four mentioned features, without a label.\n",
    "<br>\n",
    "And in order to do that, we need to train a ML algorithm with the current labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('Iris.csv')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.Species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to check if the dataset contains any null values.<br>\n",
    "If yes we have to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset shape:', iris_df.shape)\n",
    "for col in iris_df.columns:\n",
    "    print(f'NaN values count in column {col}:', iris_df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = np.max(iris_df.drop(columns=['Species', 'Id'], axis=1), axis=0)                   \n",
    "min_list = np.min(iris_df.drop(columns=['Species', 'Id'], axis=1), axis=0)                   \n",
    "normalized_iris_df = (iris_df.drop(columns=['Species', 'Id'], axis=1) - min_list) / \\\n",
    "                        (max_list - min_list)\n",
    "normalized_iris_df['Species'] = iris_df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the PetalLengthCm, PetalWidthCm and SepalLengthCm columns are highly correlated with each other<br>\n",
    "Let's visualize their correlation with the target column Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_iris_df.corr().style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that PetalLengthCm, PetalWidthCm are highly correlated with the target Species, while the SepalLengthCm is correlated enough<br>\n",
    "The SepalWidthCm is not<br>\n",
    "Let's see how our models perform on such features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (25, 12)) \n",
    "sns.countplot(x=\"SepalLengthCm\", data=normalized_iris_df, hue=\"Species\",\n",
    "                palette=\"hls\", ax=ax1)\n",
    "sns.countplot(x=\"SepalWidthCm\", data=normalized_iris_df, hue=\"Species\",\n",
    "                palette=\"hls\", ax=ax2)\n",
    "sns.countplot(x=\"PetalLengthCm\", data=normalized_iris_df, hue=\"Species\",\n",
    "                palette=\"hls\", ax=ax3)\n",
    "sns.countplot(x=\"PetalWidthCm\", data=normalized_iris_df, hue=\"Species\",\n",
    "                palette=\"hls\", ax=ax4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (25, 12)) \n",
    "sns.boxplot(x=\"Species\", y=\"SepalLengthCm\",  data=normalized_iris_df, ax=ax1)\n",
    "sns.boxplot(x=\"Species\", y=\"SepalWidthCm\",  data=normalized_iris_df, ax=ax2)\n",
    "sns.boxplot(x=\"Species\", y=\"PetalLengthCm\",  data=normalized_iris_df, ax=ax3)\n",
    "sns.boxplot(x=\"Species\", y=\"PetalWidthCm\",  data=normalized_iris_df, ax=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is clean enough, no null values, all the feature columns have a dtype of float64, which means that there is no other type than a floating number in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With sepal_area can see better correlation values than with SepalWidthCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_iris_df.corr().style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean and normalized dataset, let's divide the dataset to X (conataining the feature columns), and y (containig the label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = normalized_iris_df.drop(columns=[\"Species\"], axis=1), iris_df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the LabelEncoder class, we tranform the categorical target column, to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "label_target = pd.DataFrame({'Label': [0,1,2], 'Target': le.classes_},\n",
    "                                columns = ['Label', 'Target']).style.hide(axis='index')\n",
    "label_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the dataset into Training Dataset and Testing dataset.<br>\n",
    "Some might argue that we needed a third Cross-Validation dataset, but we only have 150 training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify = y, random_state=0)\n",
    "print('Training dataset:', X_train.shape)\n",
    "print('Test dataset:', X_test.shape)\n",
    "print('Training labels:', y_train.shape)\n",
    "print('Test labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is two functions:\n",
    "* plot_learning_results(model, X_train, X_test, y_train, y_test, classes), which plots the following:\n",
    "    * The Confusion Matrix from [Yellowbrick](https://www.scikit-yb.org/en/latest/api/classifier/confusion_matrix.html). The confusion matrix gives us the following results:<br>\n",
    "        **True Positive: TP**<br>\n",
    "        Interpretation: The model predicted positive and it’s true.<br>\n",
    "        The model correctly predicted that the Iris flower is of a certain category\n",
    "\n",
    "        **True Negative: TN**<br>\n",
    "        Interpretation: The model predicted negative and it’s true.<br>\n",
    "        The model correctly predicted that the Iris flower is not of a certain category\n",
    "\n",
    "\n",
    "        **False Positive: (Type I Error) FP**<br>\n",
    "        Interpretation: The model predicted positive and it’s false.<br>\n",
    "        The model falsly predicted that the Iris flower is of a certain category\n",
    "\n",
    "        **False Negative: (Type II Error) FN**<br>\n",
    "        Interpretation: The model predicted negative and it’s false.<br>\n",
    "        The model falsly predicted that the Iris flower is not of a certain category\n",
    "    * The Learning Curve from [Yellowbrick](https://www.scikit-yb.org/en/latest/api/model_selection/learning_curve.html).<br>\n",
    "        Line plot of learning (y-axis) over experience (x-axis).\n",
    "        Learning curves are widely used in machine learning for algorithms that learn (optimize their internal parameters) incrementally over time, such as deep learning neural networks. It gives us two curves:<br>\n",
    "\n",
    "        **Train Learning Curve:** Learning curve calculated from the training dataset that gives an idea of how well the model is learning.<br>\n",
    "        \n",
    "        **Validation Learning Curve:** Learning curve calculated from a hold-out validation dataset that gives an idea of how well the model is generalizing.\n",
    "    * The Precision-Recall Curve from [Yellowbrick](https://www.scikit-yb.org/en/latest/api/classifier/prcurve.html)<br>\n",
    "        Shows the tradeoff between a classifier’s precision, a measure of result relevancy, and recall, a measure of completeness. For each class, precision is defined as the ratio of TP to the sum of true and FP, and recall is the ratio of TP to the sum of TP and FN (see Confusion Matrix).\n",
    "        \n",
    "        **Precision** can be seen as a measure of a classifier’s exactness. For each class, it is defined as the ratio of TP to the sum of true and FP. Said another way, “for all instances classified positive, what percent was correct?”\n",
    "        $$\\begin{align*} \n",
    "        \\;  Precision &= \\frac{TP}{TP + FP} \\newline \n",
    "        \\end{align*}$$\n",
    "        **Recall** is a measure of the classifier’s completeness; the ability of a classifier to correctly find all positive instances. For each class, it is defined as the ratio of TP to the sum of TP and FN. Said another way, “for all instances that were actually positive, what percent was classified correctly?”\n",
    "        $$\\begin{align*} \n",
    "        \\;Recall &= \\frac{TP}{TP + FN}  \\newline \n",
    "        \\end{align*}$$\n",
    "        **Average precision** expresses the precision-recall curve in a single number, which represents the area under the curve. It is computed as the weighted average of precision achieved at each threshold, where the weights are the differences in recall from the previous thresholds.\n",
    "        $$\\begin{align}\n",
    "        \\; Average\\space Precision &= \\sum\\limits_{n} (Recall_{n} - Recall_{n-1})Precision_{n}\\newline\n",
    "        \\end{align}$$\n",
    "        Both Precision and Recall vary between 0 and 1.\n",
    "    * The AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve also written as AUROC (Area Under the Receiver Operating Characteristics) from [Yellowbrick](https://www.scikit-yb.org/en/latest/api/classifier/rocauc.html)<br>\n",
    "        It is a performance metric that used to evaluate classification models.<br>\n",
    "        The worst AUROC is 0.5, and the best AUROC is 1.0\n",
    "        * An AUROC of 0.5 corresponds to a coin flip, i.e. a useless model.<br>\n",
    "        * An AUROC less than 0.7 is sub-optimal performance<br>\n",
    "        * An AUROC of 0.70 – 0.80 is good performance<br>\n",
    "        * An AUROC greater than 0.8 is excellent performance<br>\n",
    "        * An AUROC of 1.0 corresponds to a perfect classifier<br><br>\n",
    "    * Training and Testing loss functions in case the model is the XGBoost's XGBClassifer\n",
    "        If both the Testing loss and the Training loss are high, then our model is Biased or Underfitted. The model is unable to accurately model the training data, and hence generates large errors.\n",
    "        If the Training loss is low and the Testing loss is much higher then our model has high Variance or is Overfitted. The model did well on the Training dataset, but poorly on the Testing data.\n",
    "        If both the Testing loss and the Training loss are low, then we a good fitted model.\n",
    "    * The [decision tree shape](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) in case the model is a DecisionTreeClassifier\n",
    "* model_report(y_pred, y_test), which return the accuracy score of the model, and the classification report (Confusion matrix report)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_results(model, X_train, X_test, y_train, y_test, classes):\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "\n",
    "    cm_matrix = ConfusionMatrix(model, ax=ax1, is_fitted=True, classes=classes, \n",
    "                                    title='Confusion Matrix')\n",
    "    cm_matrix.class_counts_ = len(le.classes_)\n",
    "    cm_matrix.score(X_test.values, y_test)\n",
    "    cm_matrix.finalize()\n",
    "\n",
    "    ln_curve = LearningCurve(model, ax=ax2, is_fitted=False, classes=classes, \n",
    "                                    title='Learning Curve')\n",
    "    ln_curve.fit(np.concatenate([X_train.values, X_test.values]), \n",
    "                    np.concatenate([y_train, y_test]))\n",
    "    ln_curve.finalize()\n",
    "    pr_re = PrecisionRecallCurve(model, ax=ax3, classes=classes, ap_score = True,\n",
    "                                    iso_f1_curves = True, title='Precision Recall', \n",
    "                                    per_class=True, micro=False, \n",
    "                                    colors=[\"purple\", \"cyan\", \"blue\"],)\n",
    "    pr_re.class_counts_ = len(le.classes_)\n",
    "    pr_re.fit(X_train.values, y_train)\n",
    "    pr_re.score(X_test.values, y_test)\n",
    "    pr_re.finalize()\n",
    "\n",
    "    auc_roc = ROCAUC(model, ax=ax4, classes=classes, is_fitted=True, micro=False,\n",
    "                                    title='Precision Recall', per_class=True,\n",
    "                                    colors=[\"purple\", \"cyan\", \"blue\"],)\n",
    "    auc_roc.class_counts_ = len(le.classes_)\n",
    "    auc_roc.target_type_ = 'multiclass'\n",
    "    auc_roc.score(X_test.values, y_test)\n",
    "    auc_roc.finalize()\n",
    "\n",
    "    if isinstance(model, XGBClassifier):\n",
    "        results = model.evals_result()\n",
    "        epochs = len(results['validation_0']['merror'])\n",
    "        x_axis = range(0, epochs)\n",
    "\n",
    "        ax5.plot(x_axis, results['validation_0']['mlogloss'], label='Train')\n",
    "        ax5.plot(x_axis, results['validation_1']['mlogloss'], label='Test')\n",
    "        ax5.legend()\n",
    "        ax5.set_ylim([0, 1])\n",
    "        ax5.set_ylabel('Log Loss')\n",
    "        ax5.set_title('XGBoost Log Loss')\n",
    "\n",
    "        ax6.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "        ax6.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "        ax6.legend()\n",
    "        ax6.set_ylim([0, 1])\n",
    "        ax6.set_ylabel('Classification Error')\n",
    "        ax6.set_title('XGBoost Classification Error')\n",
    "\n",
    "    if isinstance(model, DecisionTreeClassifier):\n",
    "        from sklearn import tree\n",
    "        tree.plot_tree(model, ax=ax5)\n",
    "\n",
    "    plt.tight_layout();\n",
    "\n",
    "def model_report(y_pred, y_test):\n",
    "    return accuracy_score(y_pred, y_test), classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "model_logr.fit(X_train.values, y_train)\n",
    "\n",
    "y_pred_logr = model_logr.predict(X_test.values)\n",
    "\n",
    "y_probs = model_logr.predict_proba(X_test.values)\n",
    "\n",
    "logr_acc, rep_logr = model_report(y_pred_logr, y_test)\n",
    "print('Accuracy: {:.2f}%'.format(logr_acc*100))\n",
    "print('Classification report')\n",
    "print(rep_logr)\n",
    "plot_learning_results(model_logr, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, classes=le.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_svm = SVC(kernel='poly', degree=3, C=1)\n",
    "model_svm.fit(X_train.values, y_train)\n",
    "\n",
    "y_pred_svm = model_svm.predict(X_test.values)\n",
    "\n",
    "svm_acc, rep_svm = model_report(y_pred_svm, y_test)\n",
    "print('Accuracy: {:.2f}%'.format(svm_acc*100))\n",
    "print('Classification report')\n",
    "print(rep_svm)\n",
    "plot_learning_results(model_svm, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, classes=le.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dt = DecisionTreeClassifier(random_state = 0, splitter = 'random',)\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model_dt.fit(X_train.values, y_train,)\n",
    "y_pred_dt = model_dt.predict(X_test.values)\n",
    "\n",
    "dt_acc, rep_dt = model_report(y_pred_dt, y_test)\n",
    "print('Accuracy: {:.2f}%'.format(dt_acc*100))\n",
    "print('Classification report')\n",
    "print(rep_dt)\n",
    "plot_learning_results(model_dt, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, classes=le.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "\n",
    "model_xgb = XGBClassifier(eval_metric=[\"merror\", \"mlogloss\"], n_jobs=-1, num_class=len(le.classes_))\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model_xgb.fit(X_train, y_train, eval_set=eval_set, verbose=0)\n",
    "y_pred_xgb = model_xgb.predict(X_test.values)\n",
    "\n",
    "xgb_acc, rep_xgb = model_report(y_pred_xgb, y_test)\n",
    "print('Accuracy: {:.2f}%'.format(xgb_acc*100))\n",
    "print('Classification report')\n",
    "print(rep_xgb)\n",
    "plot_learning_results(model_xgb, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, classes=le.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_xgb.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the Accuracy of the four Supervised Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({'Model': ['Logistic Regression', 'Support Vector Machine', 'Decision Tree', 'XGBoost'], \n",
    "                        'Accuracy': [\"%.2f\" % logr_acc, \"%.2f\" % svm_acc, \"%.2f\" % dt_acc, \"%.2f\" % xgb_acc]})\n",
    "\n",
    "compare.sort_values(by = 'Accuracy', ascending = False).style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Unsupervised Learning Algorithm\n",
    "#### The K-means\n",
    "First I implemented the algorithm with Numpy and plotted it with Seaborn and Matplotlib (Inspired by the Machine Learning Specialization mentioned at the begining of the notebook)\n",
    "Then used the sklearn framework and got the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_closest_centroids(X, centroids):\n",
    "    K = centroids.shape[0]\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distance = [] \n",
    "        for j in range(centroids.shape[0]):\n",
    "            norm_ij = np.linalg.norm(X[i] - centroids[j])\n",
    "            distance.append(norm_ij)\n",
    "        idx[i] = np.argmin(distance)\n",
    "    return idx\n",
    "    \n",
    "def compute_centroids(X, idx, K):\n",
    "    m, n = X.shape\n",
    "    centroids = np.zeros((K, n))\n",
    "    for k in range(K):   \n",
    "        points = X[idx==k]\n",
    "        centroids[k] = np.mean(points, axis = 0)     \n",
    "    return centroids\n",
    "\n",
    "def draw_line(p1, p2, ax):\n",
    "    ax.plot([p1[2], p2[2]], [p1[3], p2[3]], '-k', linewidth=1)\n",
    "\n",
    "def plot_progress_kMeans(X, centroids, previous_centroids, idx, ax):\n",
    "    colormap = np.array(['r', 'g', 'b'])\n",
    "    ax.scatter(X[:, 2], X[:, 3], c=colormap[idx], s = 30, edgecolors=\"face\")\n",
    "    ax.scatter(centroids[:, 2], centroids[:, 3], c='black', marker='x')\n",
    "    for j in range(centroids.shape[0]):\n",
    "        draw_line(centroids[j, :], previous_centroids[j, :], ax=ax)\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    m, n = X.shape\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    previous_centroids = centroids    \n",
    "    idx = np.zeros(m)\n",
    "    for i in range(max_iters):\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        plot_progress_kMeans(X, centroids, previous_centroids, idx, ax)\n",
    "        previous_centroids = centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    ax.set_xlabel('PetalLengthCm')\n",
    "    ax.set_ylabel('PetalWidthCm')\n",
    "    custom_lines = [Line2D([0], [0], marker='o', color='w', markerfacecolor='r', markersize=7),\n",
    "                    Line2D([0], [0], marker='o', color='w', markerfacecolor='g', markersize=7),\n",
    "                    Line2D([0], [0], marker='o', color='w', markerfacecolor='b', markersize=7),\n",
    "                    Line2D([0], [0], color='black', markersize=7),\n",
    "                          ]\n",
    "    ax.legend(custom_lines, ['Iris-setosa', 'Iris-virginica', 'Iris-versicolour', 'Centroids progession'])\n",
    "    plt.tight_layout(); \n",
    "    return centroids, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do no need to split the data, nor the labels of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First five elements of X are:\\n\", X[:5]) \n",
    "print('The shape of X is:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by randomly selecting initial centroids points, and iteration number.<br>\n",
    "In the plot we can see where the centroids started, and how they moved upon each iteration based on the minimum norm value of the distance (difference) between the centroids and points (records)<br>\n",
    "Finally they settled each in the center of its own cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_centroids = np.array([[5.5,2.0,2.0,0.2], [5.7,3.7,1.2,1], [6.5,2.5,4.3,2]])\n",
    "max_iters = 20\n",
    "centroids, idx = run_kMeans(X.to_numpy(), initial_centroids, max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn's KMeans class, we first fit the model with a range from 1 to 11 clusters, and then use the KElbowVisualizer to find the correct number of clusters.<br>\n",
    "[KElbowVisualizer](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) implements the [Elbow method](https://www.analyticsvidhya.com/blog/2021/01/in-depth-intuition-of-k-means-clustering-algorithm-in-machine-learning/) to help  select the optimal number of clusters by fitting the model with a range of values for. If the line chart resembles an arm, then the “elbow” (the point of inflection on the curve) is a good indication that the underlying model fits best at that point. In the visualizer “elbow” will be annotated with a dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(random_state = 0)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "model = KElbowVisualizer(kmeans, k = (1, 11))\n",
    "model.fit(X)\n",
    "model.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the correct number of clusters, we refit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = KMeans(random_state = 0, n_clusters = 3)\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot and we see we have the same result as the numpy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Clusters in Scatter Plot ---\n",
    "plt.scatter(X.to_numpy()[y_kmeans == 0, 2], X.to_numpy()[y_kmeans == 0, 3], s = 50, c = 'r', label = 'Iris-setosa')\n",
    "plt.scatter(X.to_numpy()[y_kmeans == 1, 2], X.to_numpy()[y_kmeans == 1, 3], s = 50, c = 'g', label = 'Iris-versicolour')\n",
    "plt.scatter(X.to_numpy()[y_kmeans == 2, 2], X.to_numpy()[y_kmeans == 2, 3], s = 50, c = 'b', label = 'Iris-virginica')\n",
    "\n",
    "# --- Plotting Centroids of Each Clusters ---\n",
    "plt.scatter(kmeans.cluster_centers_[:, 2], kmeans.cluster_centers_[:,3], s = 75, c = 'black', label = 'Centroids', marker='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('PetalLengthCm')\n",
    "plt.ylabel('PetalWidthCm')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
